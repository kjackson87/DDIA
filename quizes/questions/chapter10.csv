What are the three main types of data processing systems discussed in the chapter and how do they differ?;<p>The three types are:</p><ol><li>Services (online systems) - Wait for requests and handle them as quickly as possible</li><li>Batch processing systems (offline systems) - Take large input datasets and produce outputs, with jobs taking minutes to days</li><li>Stream processing systems (near-real-time systems) - Process data shortly after events happen</li></ol><p><i>(Reference: CHAPTER 10 Batch Processing, p. 389-390)</i></p>
What are the key principles of Unix tools that influenced MapReduce and modern batch processing?;<p>Key Unix principles include:</p><ul><li>Make each program do one thing well</li><li>Expect output of every program to become input to another program</li><li>Design and build software to be tried early</li><li>Use tools in preference to unskilled help</li></ul><p>These principles emphasize automation, rapid prototyping, incremental iteration, and breaking down large projects into manageable chunks.</p><p><i>(Reference: The Unix Philosophy, p. 394)</i></p>
What are the two main problems that distributed batch processing frameworks need to solve?;<p>The two main problems are:</p><ol><li>Partitioning - Bringing related data together in the same place</li><li>Fault tolerance - Handling failed tasks and ensuring jobs complete successfully</li></ol><p><i>(Reference: Summary, p. 429)</i></p>
What are the three main types of joins in MapReduce, and how do they work?;<p>The three types are:</p><ol><li>Sort-merge joins - Both inputs are partitioned and sorted by key, then merged</li><li>Broadcast hash joins - Small input is loaded into memory hash table and broadcast to all partitions of large input</li><li>Partitioned hash joins - Both inputs are partitioned in same way, each partition processed independently</li></ol><p><i>(Reference: Map-Side Joins, p. 409-410)</i></p>
Why is materializing intermediate state in MapReduce jobs sometimes problematic?;<p>Materializing intermediate state has several downsides:</p><ul><li>Jobs must wait for all tasks in preceding jobs to complete before starting</li><li>Mappers are often redundant, just reading back reducer output</li><li>Storing intermediate state in distributed filesystem means unnecessary replication</li><li>Writing to disk between stages slows down processing</li></ul><p><i>(Reference: Materialization of Intermediate State, p. 419-420)</i></p>
What are the key advantages of dataflow engines like Spark, Tez and Flink over MapReduce?;<p>Key advantages include:</p><ul><li>Sorting only performed when required</li><li>Unnecessary map tasks eliminated</li><li>Better scheduling through explicit declaration of data dependencies</li><li>Less disk I/O by keeping intermediate state in memory</li><li>Operators can start as soon as their inputs are ready</li><li>Better process reuse reducing startup overhead</li></ul><p><i>(Reference: Dataflow engines, p. 421-422)</i></p>
What is the Pregel model and how does it handle graph processing?;<p>The Pregel model is a bulk synchronous parallel processing approach where:</p><ul><li>Vertices can send messages to other vertices</li><li>Processing happens in rounds/iterations</li><li>Each vertex processes received messages and updates its state</li><li>Vertices remember state between iterations</li><li>Framework handles fault tolerance through checkpointing</li></ul><p><i>(Reference: The Pregel processing model, p. 425-426)</i></p>
How do modern batch processing frameworks handle fault tolerance?;<p>Modern frameworks use different approaches:</p><ul><li>MapReduce writes intermediate state to disk for easy recovery</li><li>Spark uses RDDs (Resilient Distributed Datasets) to track data lineage</li><li>Flink uses checkpoints of operator state</li><li>All ensure exactly-once processing semantics</li><li>Deterministic operations are preferred to avoid cascading failures</li></ul><p><i>(Reference: Fault tolerance, p. 422-423)</i></p>
What is the key difference between batch processing and stream processing?;<p>The key difference is that:</p><ul><li>Batch processing operates on bounded data (fixed-size input)</li><li>Stream processing operates on unbounded data (never-ending input)</li></ul><p>Batch jobs eventually complete when they process all input, while streaming jobs continue indefinitely.</p><p><i>(Reference: Summary, p. 430)</i></p>
How does the Unix philosophy of composability compare to modern batch processing systems?;<p>The Unix philosophy emphasizes:</p><ul><li>Programs that do one thing well</li><li>Programs that work together through simple interfaces (files/pipes)</li><li>Programs that handle text streams as universal interface</li></ul><p>Similarly, batch processing systems use distributed filesystems as their interface, allowing different tools and jobs to be composed together.</p><p><i>(Reference: The Unix Philosophy, p. 394-396)</i></p>
What are the key differences between MapReduce/Hadoop systems and MPP databases?;<p>Key differences include:</p><ul><li>Data model flexibility (Hadoop allows any format, MPP requires specific schema)</li><li>Processing model diversity (Hadoop allows arbitrary code, MPP mainly SQL)</li><li>Fault tolerance approach (Hadoop task-level, MPP query-level)</li><li>Resource management (Hadoop designed for multi-tenant clusters with preemption)</li></ul><p><i>(Reference: Comparing Hadoop to Distributed Databases, p. 414-418)</i></p>
What are the common types of outputs from batch processing jobs and how are they handled?;<p>Common outputs include:</p><ul><li>Search indexes (like Lucene)</li><li>Machine learning models</li><li>Structured databases for serving systems</li></ul><p>These are typically materialized as files in distributed storage first, then bulk loaded into specialized serving systems.</p><p><i>(Reference: The Output of Batch Workflows, p. 411-413)</i></p>
How do modern batch processing systems handle skewed data?;<p>Systems handle skew through:</p><ul><li>Detecting hot keys through sampling</li><li>Splitting hot keys across multiple reducers</li><li>Using different strategies for hot and normal keys</li><li>Two-stage aggregation for grouped data</li></ul><p><i>(Reference: Handling skew, p. 407-408)</i></p>
How have high-level APIs and languages evolved in batch processing systems?;<p>Evolution includes:</p><ul><li>Development of languages like Hive, Pig, and Cascading</li><li>Movement toward declarative query languages</li><li>Integration of query optimization</li><li>Specialization for different domains (machine learning, statistical analysis)</li><li>Balance between declarative and imperative programming models</li></ul><p><i>(Reference: High-Level APIs and Languages, p. 426-428)</i></p>