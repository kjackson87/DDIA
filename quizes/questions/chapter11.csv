What is stream processing and how does it differ from batch processing?;<p>Stream processing:</p><ul><li>Processes data continuously and incrementally as it arrives</li><li>Handles unbounded datasets that are never "complete"</li><li>Unlike batch processing, can't wait for all input data before starting</li><li>Often used for data that arrives gradually over time (user activity, sensor readings, etc.)</li></ul><p><i>(Ref: Stream Processing, p. 439)</i></p>
What are the two main types of message brokers and how do they differ?;<p>Two types of message brokers:</p><ul><li>AMQP/JMS-style: Assigns individual messages to consumers, deletes messages once acknowledged</li><li>Log-based: Assigns all messages in a partition to same consumer, maintains message ordering, retains messages on disk</li></ul><p><i>(Ref: Messaging Systems, p. 441-443)</i></p>
What is change data capture (CDC) and why is it useful?;<p>Change data capture (CDC):</p><ul><li>Process of observing all data changes written to a database</li><li>Allows changes to be replicated to other systems</li><li>Enables keeping search indexes, caches, and data warehouses in sync</li><li>Makes database changes available as a stream</li></ul><p><i>(Ref: Change Data Capture, p. 454-455)</i></p>
What is event sourcing and how does it differ from change data capture?;<p>Event sourcing:</p><ul><li>Application logic explicitly built on immutable events written to event log</li><li>Events reflect things that happened at application level</li><li>Updates and deletes are discouraged</li><li>Unlike CDC, which captures low-level state changes from database</li></ul><p><i>(Ref: Event Sourcing, p. 457-458)</i></p>
What are the three types of stream joins?;<p>Three types of stream joins:</p><ul><li>Stream-stream joins: Match related events within time windows</li><li>Stream-table joins: Enrich stream events with data from database</li><li>Table-table joins: Both inputs are database changelogs, result is stream of changes to materialized view</li></ul><p><i>(Ref: Stream Joins, p. 472-475)</i></p>
What are the main types of windows in stream processing?;<p>Types of windows:</p><ul><li>Tumbling window: Fixed length, no overlap</li><li>Hopping window: Fixed length with overlap</li><li>Sliding window: Contains events within some interval of each other</li><li>Session window: Variable length, grouped by user activity with timeout</li></ul><p><i>(Ref: Types of windows, p. 472-473)</i></p>
What are the main challenges with handling time in stream processing?;<p>Time handling challenges:</p><ul><li>Processing time vs event time discrepancy</li><li>Dealing with straggler events that arrive late</li><li>Knowing when you have received all events for a window</li><li>Handling events from devices with incorrect clocks</li></ul><p><i>(Ref: Reasoning About Time, p. 468-471)</i></p>
What are the approaches to achieving fault tolerance in stream processing?;<p>Fault tolerance approaches:</p><ul><li>Microbatching: Breaking stream into small batches</li><li>Checkpointing: Periodically saving state</li><li>Atomic commits: Ensuring all effects of processing happen or none do</li><li>Idempotence: Making operations safe to repeat</li></ul><p><i>(Ref: Fault Tolerance, p. 476-479)</i></p>
What are the main uses of stream processing?;<p>Main uses:</p><ul><li>Complex event processing (CEP): Pattern matching in event streams</li><li>Stream analytics: Computing aggregations and statistics</li><li>Maintaining materialized views: Keeping derived data systems updated</li><li>Search on streams: Continuous search queries on event streams</li></ul><p><i>(Ref: Uses of Stream Processing, p. 465-468)</i></p>
What is log compaction and how does it work?;<p>Log compaction:</p><ul><li>Storage engine periodically looks for records with same key</li><li>Keeps only the most recent update for each key</li><li>Discards duplicates during compaction and merging process</li><li>Allows efficient rebuilding of state while maintaining current values</li></ul><p><i>(Ref: Log compaction, p. 456)</i></p>
What are consumer offsets and why are they important?;<p>Consumer offsets:</p><ul><li>Track which messages have been processed in a partition</li><li>Allow consumers to resume processing after failure</li><li>Similar to log sequence numbers in database replication</li><li>Enable consumer groups to coordinate message processing</li></ul><p><i>(Ref: Consumer offsets, p. 449-450)</i></p>
How do stream processors handle state?;<p>Stream processor state handling:</p><ul><li>Can keep state in local or remote storage</li><li>Local state must be replicated for fault tolerance</li><li>Can rebuild state from input streams</li><li>May use periodic snapshots for faster recovery</li></ul><p><i>(Ref: Rebuilding state after a failure, p. 478-479)</i></p>
What is the difference between commands and events in stream processing?;<p>Commands vs Events:</p><ul><li>Commands: Initial requests that may fail validation</li><li>Events: Immutable facts about things that have happened</li><li>Commands become events after validation</li><li>Events cannot be rejected by consumers</li></ul><p><i>(Ref: Commands and events, p. 459)</i></p>
What are the problems with dual writes in streaming systems?;<p>Dual write problems:</p><ul><li>Race conditions between writes to different systems</li><li>One write may succeed while another fails</li><li>Can lead to inconsistencies between systems</li><li>Difficult to atomically commit to multiple systems</li></ul><p><i>(Ref: Keeping Systems in Sync, p. 452-453)</i></p>