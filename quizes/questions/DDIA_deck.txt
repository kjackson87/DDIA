#separator:tab
#html:true
#tags column:5
What are the three key concerns for data systems discussed in the chapter?	Reliability, Scalability, and Maintainability	6		chapter::1
How does the book define reliability?	The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error).	6		chapter::1
What is the difference between a fault and a failure?	A fault is usually defined as one component of the system deviating from its spec, whereas a failure is when the system as a whole stops providing the required service to the user.	7		chapter::1
What are the three types of faults discussed in the chapter?	Hardware faults, Software errors, and Human errors	7-10		chapter::1
What is the difference between scaling up and scaling out?	Scaling up (vertical scaling) refers to moving to a more powerful machine, while scaling out (horizontal scaling) refers to distributing the load across multiple smaller machines.	17		chapter::1
What is tail latency amplification?	"It&#x27;s an effect where a small percentage of slow backend calls can cause a higher proportion of end-user requests to be slow, especially when an end-user request requires multiple backend calls."	16		chapter::1
What are the three design principles for software systems that can help with maintainability?	Operability, Simplicity, and Evolvability	19		chapter::1
How does the book define accidental complexity?	Accidental complexity is complexity that is not inherent in the problem that the software solves (as seen by the users) but arises only from the implementation.	21		chapter::1
What is meant by evolvability in the context of data systems?	Evolvability refers to making it easy for engineers to make changes to the system in the future, adapting it for unanticipated use cases as requirements change.	22		chapter::1
What are percentiles used for in measuring response times?	Percentiles are used to measure the distribution of response times and understand the experience of typical and outlier requests. For example, the 95th percentile response time means 95% of requests are faster than this time.	14-16		chapter::1
What are the three main data models discussed in the chapter?	The relational model, the document model, and graph-based data models.	28		chapter::1
What was the main purpose of the relational model when it was introduced?	To hide implementation details behind a cleaner interface and provide a more abstract way of working with data.	28		chapter::1
What are some of the driving forces behind the adoption of NoSQL databases?	Greater scalability, preference for free and open-source software, specialized query operations, and frustration with the restrictiveness of relational schemas.	29		chapter::1
What is the difference between the document data model and the relational model in handling one-to-many relationships?	The document model can store nested records (one-to-many relationships) within the parent record, while the relational model typically requires separate tables linked by foreign keys.	38		chapter::1
"What is meant by &#x27;schema-on-read&#x27; versus &#x27;schema-on-write&#x27;?"	Schema-on-read means the structure of the data is implicit and only interpreted when the data is read, while schema-on-write means the schema is explicit and enforced when data is written to the database.	40		chapter::1
What are the main components of a property graph model?	Vertices (with a unique identifier and a set of properties) and edges (with a unique identifier, start and end vertices, a label, and a set of properties).	50		chapter::1
How does a triple-store model differ from a property graph model?	A triple-store model represents all data in the form of (subject, predicate, object) triples, while a property graph model uses separate concepts for vertices and edges with their properties.	56		chapter::1
What is the difference between a declarative query language and an imperative code approach?	A declarative query language specifies the pattern of data you want and what conditions the results must meet, while an imperative approach tells the computer exactly how to perform operations to get the desired result.	43		chapter::1
What are the two main categories of storage engines discussed in the chapter?	Storage engines optimized for transaction processing (OLTP) and those optimized for analytics (OLAP).	90		chapter::3
What is a key difference between OLTP and OLAP in terms of data access patterns?	OLTP systems typically process a large number of small operations, each touching a small amount of data, while OLAP systems process fewer but larger operations that scan over a large portion of the dataset.	90		chapter::3
What are the two main schools of thought for OLTP storage engines?	The log-structured school (which only permits appending to files and deleting obsolete files) and the update-in-place school (which treats the disk as a set of fixed-size pages that can be overwritten).	103		chapter::3
What is a key advantage of log-structured storage engines?	They turn random-access writes into sequential writes on disk, which enables higher write throughput due to the performance characteristics of hard drives and SSDs.	103		chapter::3
What is a data warehouse and how does it differ from OLTP systems?	"A data warehouse is a separate database containing a read-only copy of data from OLTP systems, optimized for analytics. Unlike OLTP systems, it&#x27;s designed to handle complex queries that scan large portions of the dataset."	91-92		chapter::3
What is column-oriented storage and why is it beneficial for analytical queries?	"Column-oriented storage is a technique where data is stored by column rather than by row. It&#x27;s beneficial for analytical queries because it allows the database to read only the columns needed for a query, reducing I/O and improving query performance."	95-96		chapter::3
What is a B-tree and how does it differ from log-structured indexes?	A B-tree is a self-balancing tree data structure that keeps data sorted and allows searches, sequential access, insertions, and deletions in logarithmic time. Unlike log-structured indexes, B-trees update data in-place, breaking the database down into fixed-size pages.	79-80		chapter::3
What is write amplification and why is it a concern in storage systems?	"Write amplification is when a write to the database results in multiple writes to the disk over the course of the database&#x27;s lifetime. It&#x27;s a concern because it can reduce write throughput and cause faster wear on SSDs."	84		chapter::3
What is a star schema in the context of data warehouses?	A star schema is a data modeling technique used in data warehouses. It consists of one or more fact tables referencing any number of dimension tables, creating a star-like structure. This schema simplifies queries and provides fast aggregations.	93-95		chapter::3
What is a data cube and how does it relate to materialized views?	"A data cube is a multi-dimensional aggregation of data, pre-computing aggregates along various dimensions. It&#x27;s a special case of a materialized view, which is a cached result of a query. Data cubes can significantly speed up certain types of analytical queries."	101-102		chapter::3
What are the two main ways data is typically represented in an application?	 1) In memory, as objects/data structures<br>2) When writing to a file or sending over the network, as a self-contained sequence of bytes<br>(p. 112)			
What is encoding (in the context of data representation)?	 The translation from in-memory representation to a byte sequence<br>(p. 113)			
What are the main problems with language-specific encoding formats?	 - Tied to a particular programming language<br>- Often have security vulnerabilities<br>- Versioning is often an afterthought<br>- Efficiency is often poor<br>(p. 113-114)			
What are the advantages of using schema-based binary encoding formats like Protocol Buffers, Thrift, or Avro?	 - More compact than JSON and XML<br>- Schema is a form of documentation<br>- Schema enables type checking<br>- Better support for schema evolution<br>(p. 127-128)			
How do Thrift and Protocol Buffers handle schema evolution?	 - Each field is identified by a tag number<br>- New fields can be added with new tag numbers<br>- Old code ignores fields it doesn't recognize<br>- Field removal is only possible for optional fields<br>(p. 120-121)			
How does Avro handle schema evolution without using tag numbers?	 - It uses a writer's schema and a reader's schema<br>- When decoding, Avro resolves differences between the two schemas<br>- Fields can be added or removed if they have a default value<br>(p. 123-124)			
What are the three main modes of dataflow covered in the chapter?	 1) Databases (process writes, another reads)<br>2) RPC and REST APIs (client encodes request, server decodes and responds)<br>3) Asynchronous message passing (sender encodes, recipient decodes)<br>(p. 129-136)			
What is the difference between backward compatibility and forward compatibility?	 - Backward compatibility: Newer code can read data encoded by older code<br>- Forward compatibility: Older code can read data encoded by newer code<br>(p. 112)			
What are the main advantages of using a message broker for communication between services?	 - Acts as a buffer if recipient is unavailable<br>- Can automatically redeliver messages<br>- Avoids sender needing to know IP/port of recipient<br>- Allows one message to be sent to multiple recipients<br>- Logically decouples sender from recipient<br>(p. 137)			
What is the key idea behind the actor model for concurrency?	 Logic is encapsulated in actors, which communicate through asynchronous message passing, avoiding shared state and the complexities of traditional multithreading<br>(p. 138)			
What are the three main purposes of replication?	1. High availability 2. Disconnected operation 3. Latency reduction (Page 151)			chapter::5
What are the three main approaches to replication discussed in the chapter?	1. Single-leader&nbsp;<div>2. Multi-leader&nbsp;</div><div>3. Leaderless replication&nbsp;</div><div>(Page 192)</div>			chapter::5
In single-leader replication, what is the role of the leader?	Handles all writes, sends data change events to followers. Reads can be from any replica, but may be stale from followers. (Page 192)			chapter::5
What is the key challenge with asynchronous replication?	Recently committed data may be lost if an asynchronously updated follower becomes the new leader after a failure. (Page 193)			chapter::5
What is the quorum condition for reads and writes in a leaderless system with n replicas?	w + r &gt; n, where w is write acknowledgments and r is nodes queried for a read. (Page 179-180)			chapter::5
What is read-after-write consistency?	Users always see their own updates when reloading a page. (Page 193)			chapter::5
What is the purpose of version vectors in leaderless replication?	Track causal dependencies between data versions, distinguishing overwrites from concurrent writes. (Page 191)			chapter::5
What are siblings in the context of leaderless databases?	Conflicting data versions from concurrent writes that may need merging by the application. (Page 190)			chapter::5
"What is the &#x27;last write wins&#x27; (LWW) conflict resolution strategy?"	Resolves conflicts by choosing the write with the latest timestamp, risking data loss. (Page 186)			chapter::5
What is hinted handoff in the context of sloppy quorums?	Temporary storage of writes for unavailable nodes, forwarded when the node recovers.&nbsp;<div>(Page 183-184)</div>			chapter::5
What is partitioning in the context of databases, and why is it used?	<p>Partitioning is the process of breaking a large database into smaller subsets called partitions. It's used to improve scalability when data volume is too large for a single machine.</p><p><i>(Reference: Partitioning, p. 199)</i></p>			chapter::6
What are the two main approaches to partitioning data?	<p>The two main approaches to partitioning data are:</p><ol><li>Key range partitioning</li><li>Hash partitioning</li></ol><p><i>(Reference: Partitioning of Key-Value Data, p. 201-203)</i></p>			chapter::6
What is the main advantage and disadvantage of key range partitioning?	<p><strong>Advantage:</strong></p><ul><li>It allows efficient range queries</li></ul><p><strong>Disadvantage:</strong></p><ul><li>It can lead to hot spots if keys are accessed together frequently</li></ul><p><i>(Reference: Partitioning by Key Range, p. 202-203)</i></p>			chapter::6
How does hash partitioning work, and what are its pros and cons?	<p>Hash partitioning:</p><ul><li>A hash function is applied to each key</li><li>A partition owns a range of hashes</li></ul><p><strong>Pro:</strong></p><ul><li>It distributes load more evenly</li></ul><p><strong>Con:</strong></p><ul><li>It makes range queries inefficient</li></ul><p><i>(Reference: Partitioning by Hash of Key, p. 203-204)</i></p>			chapter::6
What is consistent hashing and why is it rarely used in practice for databases?	<p>Consistent hashing is a way of evenly distributing load across an internet-wide system of caches, using randomly chosen partition boundaries. It's rarely used in practice for databases because it doesn't work very well for them.</p><p><i>(Reference: Consistent Hashing, p. 204)</i></p>			chapter::6
How can skewed workloads and hot spots be mitigated in partitioned systems?	<p>Techniques to mitigate skewed workloads and hot spots include:</p><ol><li>Adding a random number to hot keys</li><li>Splitting writes across different keys</li><li>Combining reads</li></ol><p><i>(Reference: Skewed Workloads and Relieving Hot Spots, p. 205)</i></p>			chapter::6
What are the two main approaches to partitioning secondary indexes?	<p>The two main approaches to partitioning secondary indexes are:</p><ol><li>Document-based partitioning (local indexes)</li><li>Term-based partitioning (global indexes)</li></ol><p><i>(Reference: Partitioning and Secondary Indexes, p. 206-208)</i></p>			chapter::6
What is rebalancing in partitioned databases, and what are three strategies for it?	<p>Rebalancing is moving data between nodes to maintain fair load distribution.</p><p>Three strategies for rebalancing:</p><ol><li>Fixed number of partitions</li><li>Dynamic partitioning</li><li>Partitioning proportionally to nodes</li></ol><p><i>(Reference: Rebalancing Partitions, Strategies for Rebalancing, p. 209-213)</i></p>			chapter::6
What is the main advantage of dynamic partitioning?	<p>The main advantage of dynamic partitioning is that the number of partitions adapts to the total data volume, allowing for better resource management.</p><p><i>(Reference: Dynamic partitioning, p. 212)</i></p>			chapter::6
What are the three general approaches to request routing in partitioned systems?	<p>The three general approaches to request routing in partitioned systems are:</p><ol><li>Allow clients to contact any node</li><li>Send requests to a routing tier first</li><li>Require clients to be aware of the partitioning</li></ol><p><i>(Reference: Request Routing, p. 214-215)</i></p>			chapter::6
How do massively parallel processing (MPP) relational databases handle complex queries across partitions?	<p>MPP query optimizers break complex queries into execution stages and partitions, which can be executed in parallel on different nodes.</p><p><i>(Reference: Parallel Query Execution, p. 216)</i></p>			chapter::6
What are the challenges of implementing term-partitioned secondary indexes?	<p>Challenges of implementing term-partitioned secondary indexes:</p><ol><li>Updates to global secondary indexes are often asynchronous, which can lead to inconsistencies</li><li>It may require distributed transactions across multiple partitions, which is not supported by all databases</li></ol><p><i>(Reference: Partitioning Secondary Indexes by Term, p. 208-209)</i></p>			chapter::6
What are the trade-offs between automatic and manual rebalancing?	<p>Trade-offs between automatic and manual rebalancing:</p><p><strong>Automatic rebalancing:</strong></p><ul><li>Convenient</li><li>Can be unpredictable</li><li>Potentially dangerous when combined with automatic failure detection</li></ul><p><strong>Manual rebalancing:</strong></p><ul><li>Slower</li><li>Can help prevent operational surprises</li></ul><p><i>(Reference: Operations: Automatic or Manual Rebalancing, p. 213-214)</i></p>			chapter::6
How does partitioning interact with replication in distributed databases?	<p>Partitioning is usually combined with replication so that copies of each partition are stored on multiple nodes. This improves fault tolerance but adds complexity to the system.</p><p><i>(Reference: Partitioning and Replication, p. 199-200)</i></p>			chapter::6
What are the four key properties of transactions represented by the ACID acronym?	<p>The four key properties of transactions represented by the ACID acronym are:</p><ul><li>Atomicity</li><li>Consistency</li><li>Isolation</li><li>Durability</li></ul><p><i>(Reference: The Meaning of ACID, p. 223)</i></p>			chapter::7
What does atomicity mean in the context of ACID transactions?	<p>Atomicity in the context of ACID transactions means:</p><ul><li>If a transaction fails, all of its operations are undone</li><li>The database is left in the state it was before the transaction started</li></ul><p><i>(Reference: Atomicity, p. 223-224)</i></p>			chapter::7
Compare and contrast read committed isolation and snapshot isolation. How do they prevent different types of concurrency problems?	<p>Read committed isolation:</p><ul><li>Prevents dirty reads by only showing committed data</li><li>Does not prevent nonrepeatable reads</li></ul><p>Snapshot isolation:</p><ul><li>Provides a consistent snapshot of the database at the start of the transaction</li><li>Prevents both dirty reads and nonrepeatable reads</li></ul><p><i>(Reference: No dirty reads, p. 234-235; Snapshot Isolation and Repeatable Read, p. 237-238)</i></p>			chapter::7
What is the lost update problem and how can it be prevented?	<p>The lost update problem:</p><ul><li>Occurs when two transactions read and update the same object concurrently, potentially overwriting each other's changes</li><li>Can be prevented using atomic write operations, explicit locking, or automatic detection in some isolation levels</li></ul><p><i>(Reference: Preventing Lost Updates, p. 242-243)</i></p>			chapter::7
What is write skew and why is it problematic? How does it relate to the phantom problem?	<p>Write skew:</p><ul><li>Is a concurrency anomaly where two transactions read overlapping data and make decisions based on that data, but then update different objects</li><li>Can lead to violation of application constraints</li><li>Is related to the phantom problem, where a write in one transaction changes the result of a search query in another transaction</li></ul><p><i>(Reference: Write Skew and Phantoms, p. 246-247; Phantoms causing write skew, p. 250-251)</i></p>			chapter::7
What are the three main techniques for implementing serializability, and how do they differ in their approach to concurrency control?	<p>The three main techniques for implementing serializability are:</p><ol><li>Actual serial execution (pessimistic)</li><li>Two-phase locking (2PL) (pessimistic)</li><li>Serializable snapshot isolation (SSI) (optimistic)</li></ol><p>Pessimistic approaches assume conflicts are likely and prevent them, while optimistic approaches assume conflicts are rare and check for them at commit time.</p><p><i>(Reference: Serializability, p. 251-252; Pessimistic versus optimistic concurrency control, p. 261-262)</i></p>			chapter::7
How does actual serial execution achieve serializability, and how can it be optimized for partitioned data?	<p>Actual serial execution achieves serializability by:</p><ul><li>Executing only one transaction at a time, in serial order, on a single thread</li><li>Completely avoiding concurrency issues</li></ul><p>It can be optimized for partitioned data by:</p><ul><li>Allowing each partition to have its own transaction processing thread</li><li>Enabling linear scalability with CPU cores for single-partition transactions</li></ul><p><i>(Reference: Actual Serial Execution, p. 252-253; Partitioning, p. 255-256)</i></p>			chapter::7
Explain how two-phase locking (2PL) works. What types of locks does it use, and what are its main drawbacks?	<p>Two-phase locking (2PL) works by:</p><ul><li>Acquiring locks before reading or writing data</li><li>Using shared locks for reads and exclusive locks for writes</li><li>Holding all locks until the transaction commits or aborts</li></ul><p>Main drawbacks:</p><ul><li>Significant performance and deadlock issues</li><li>Unstable latencies and very slow performance at high percentiles when there is contention</li></ul><p><i>(Reference: Implementation of two-phase locking, p. 257-258; Performance of two-phase locking, p. 258-259)</i></p>			chapter::7
What is predicate locking, and why is it typically approximated with index-range locking in practice?	<p>Predicate locking:</p><ul><li>Locks all data matching certain search conditions</li><li>Prevents phantoms by locking data that doesn't yet exist</li></ul><p>Index-range locking:</p><ul><li>Approximates predicate locking for better performance</li><li>Locks a wider range of objects than strictly necessary</li><li>Used in practice because true predicate locking is expensive to implement</li></ul><p><i>(Reference: Predicate locks, p. 259-260; Index-range locks, p. 260-261)</i></p>			chapter::7
How does serializable snapshot isolation (SSI) detect and prevent serialization conflicts? What are its performance trade-offs compared to other techniques?	<p>SSI detects serialization conflicts by:</p><ul><li>Tracking reads and writes of transactions</li><li>Detecting when a transaction has read data that was subsequently modified</li><li>Aborting transactions that may have acted on outdated information</li></ul><p>Performance trade-offs:</p><ul><li>Generally better performance than two-phase locking</li><li>Allows long-running reads without blocking writes</li><li>May have higher abort rates in high-contention scenarios</li></ul><p><i>(Reference: Serializable Snapshot Isolation (SSI), p. 261-262; Detecting stale MVCC reads, p. 263-264; Performance of serializable snapshot isolation, p. 265)</i></p>			chapter::7
